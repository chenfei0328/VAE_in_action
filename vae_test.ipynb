{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch import autograd\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms as tfs\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 100\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 1e-3\n",
    "# True表示需下载，False表示已下载\n",
    "DOWNLOAD_MNIST = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468\n",
      "torch.Size([128, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# 训练时才会标准化\n",
    "im_tfs = tfs.Compose([\n",
    "    # 先将输入归一化到(0,1)，再使用公式”(x-mean)/std”，将每个元素分布到(-1,1) \n",
    "    tfs.ToTensor(),\n",
    "    tfs.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "train_set = MNIST('./mnist', train=True, transform=im_tfs, download=DOWNLOAD_MNIST)\n",
    "train_data = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, drop_last=True)\n",
    "print(len(train_data))\n",
    "\n",
    "for i, batch in enumerate(train_data):\n",
    "    #print(i)\n",
    "    # batch[0]为数据,batch[1]为标签\n",
    "    print(batch[0].shape)\n",
    "    break\n",
    "    \n",
    "\n",
    "test_set = MNIST('./mnist', train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468\n"
     ]
    }
   ],
   "source": [
    "#print(train_set.data.size())\n",
    "#print(train_set.data[0])\n",
    "#print(train_set.targets.size())\n",
    "#print(train_set.targets[0])\n",
    "print(len(train_data))\n",
    "# plt.figure(figsize=(20, 10))\n",
    "# plt.imshow(train_set.data[0].numpy(), cmap='gray')\n",
    "# plt.title('%i' % train_set.targets[0])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, latent_num=2):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(28*28, 400)\n",
    "        self.fc21 = nn.Linear(400, 20) # mean\n",
    "        self.fc22 = nn.Linear(400, 20) # var\n",
    "        self.fc3 = nn.Linear(20, 400)\n",
    "        self.fc4 = nn.Linear(400, 28*28)\n",
    "\n",
    "    # q(z|x)\n",
    "    def encode_q(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "    \n",
    "    # 重参数化，使网络可以反向传播\n",
    "    def reparametrize(self, mu, logvar):\n",
    "        # mul逐乘\n",
    "        # exp逐指数\n",
    "        # exp_是exp的in-place形式\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        eps = torch.FloatTensor(std.size()).normal_()\n",
    "        if torch.cuda.is_available():\n",
    "            eps = eps.cuda()\n",
    "        # z = mu + sigma * eps\n",
    "        return eps.mul(std).add_(mu)\n",
    "    \n",
    "    # p(x|z)\n",
    "    def decoder_p(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        return torch.tanh(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode_q(x)\n",
    "        z = self.reparametrize(mu, logvar)\n",
    "        \n",
    "        # 解码，同时输出均值和方差\n",
    "        return self.decoder_p(z), mu, logvar \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAE(\n",
      "  (fc1): Linear(in_features=784, out_features=400, bias=True)\n",
      "  (fc21): Linear(in_features=400, out_features=20, bias=True)\n",
      "  (fc22): Linear(in_features=400, out_features=20, bias=True)\n",
      "  (fc3): Linear(in_features=20, out_features=400, bias=True)\n",
      "  (fc4): Linear(in_features=400, out_features=784, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = VAE()\n",
    "if torch.cuda.is_available():\n",
    "    net = net.cuda()\n",
    "    \n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Split: train\n",
       "    Root Location: ./mnist\n",
       "    Transforms (if any): Compose(\n",
       "                             ToTensor()\n",
       "                             Normalize(mean=[0.5], std=[0.5])\n",
       "                         )\n",
       "    Target Transforms (if any): None"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_set.data[0].view(-1, 784)\n",
    "x = x.to(dtype=torch.float32)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    x = x.cuda()\n",
    "_, mu, var = net(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 14.6022, -45.9968,   8.9362, -34.1990, -22.0062,  11.0758,  -2.4679,\n",
       "          -0.1938,  17.5876,  26.7471,   0.7580,   0.2342,  -3.3591,  -7.3759,\n",
       "         -32.6608, -19.0109,  27.5281,   2.6232,  23.3838, -13.5074]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-18.7527,   1.0859, -20.1880,   4.6355,  13.0386,  12.9033, -16.1935,\n",
       "         -18.2203, -38.4091,   0.5825,  -8.3420,  -5.8560,   2.1735,  14.7907,\n",
       "          -8.0186,   8.9145, -28.9785, -17.5274,  10.7804,  -9.6349]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_function = nn.MSELoss(reduction='sum')\n",
    "\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    MSE = reconstruction_function(recon_x, x)\n",
    "    # loss = 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n",
    "    KLD = torch.sum(KLD_element).mul_(-0.5)\n",
    "    # KL divergence\n",
    "    return MSE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_img(x):\n",
    "    x = 0.5 * (x + 1.)\n",
    "    x = x.clamp(0, 1)\n",
    "    x = x.view(x.shape[0],1,28,28)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5, Loss: 74.7497\n",
      "epoch: 10, Loss: 68.9868\n",
      "epoch: 15, Loss: 68.1801\n",
      "epoch: 20, Loss: 66.1932\n",
      "epoch: 25, Loss: 64.7258\n",
      "epoch: 30, Loss: 64.2296\n",
      "epoch: 35, Loss: 63.5790\n",
      "epoch: 40, Loss: 63.0088\n",
      "epoch: 45, Loss: 63.9606\n",
      "epoch: 50, Loss: 61.5279\n",
      "epoch: 55, Loss: 60.9257\n",
      "epoch: 60, Loss: 58.9894\n",
      "epoch: 65, Loss: 61.9385\n",
      "epoch: 70, Loss: 62.1132\n",
      "epoch: 75, Loss: 62.2782\n",
      "epoch: 80, Loss: 63.5342\n",
      "epoch: 85, Loss: 63.6882\n",
      "epoch: 90, Loss: 60.2739\n",
      "epoch: 95, Loss: 61.5337\n",
      "epoch: 100, Loss: 61.5340\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for e in range(EPOCH):\n",
    "    for i, batch in enumerate(train_data):\n",
    "        # print(i)\n",
    "        # batch[0]为数据,batch[1]为标签\n",
    "        # print(batch[0], batch[1])\n",
    "        \n",
    "#         if torch.cuda.is_available():\n",
    "#             batch = batch.cuda()\n",
    "        img = batch[0].view(BATCH_SIZE, -1)\n",
    "        #print(img.size())\n",
    "        recon_img, mu, logvar = net(img)\n",
    "        loss = loss_function(recon_img, img, mu, logvar) / BATCH_SIZE\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if (e + 1) % 5 == 0:\n",
    "        print('epoch: {}, Loss: {:.4f}'.format(e + 1, loss.data))\n",
    "        save = to_img(recon_img.cpu().data)\n",
    "        if not os.path.exists('./vae_img'):\n",
    "            os.mkdir('./vae_img')\n",
    "        save_image(save, './vae_img/image_{}.png'.format(e + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pyn/anaconda3/lib/python3.7/site-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type VAE. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "def save_model():\n",
    "    # entire net\n",
    "    torch.save(net, 'VAE_net1.pkl')\n",
    "    # parameters\n",
    "    torch.save(net.state_dict(), 'VAE_net1_params.pkl')\n",
    "    \n",
    "def restore_net():\n",
    "    net2 = torch.load('VAE_net1.pkl')\n",
    "    net2.eval()\n",
    "    \n",
    "def restore_params():\n",
    "    # 要与原net的结构一样\n",
    "    net3 = VAE(*args, **kwargs)\n",
    "    net3.load_state_dict(torch.load('VAE_net1_params.pkl'))\n",
    "    net3.eval()\n",
    "    \n",
    "save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
